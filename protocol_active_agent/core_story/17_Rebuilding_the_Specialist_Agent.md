# Protocol "Active Agent" - Core Story

## 17. Rebuilding the Specialist Agent (Log Transcript)

**Synopsis:**

*The project's focus shifts to recovering a secondary experiment lost during the chat crash: a custom AI agent designed to be an expert on the paper itself. Alexander reports that they had already made some progress on the "Echo Arena" game code but wants to first rebuild the agent. He requests the latest version of the manuscript in Markdown format to use as the agent's system prompt. The AI provides the complete, updated text and also recreates a series of five distinct test prompts designed to probe the new agent's comprehension of the theory, from basic concepts to creative applications and critical self-analysis.*

---

### Chapter 17: The Expert in a Box

With the project back on a stable footing, Alexander chose which of the five parallel tracks to pursue first. While progress had been made on the "Echo Arena" game, he wanted to first rebuild another casualty of the chat crash: a specialized AI agent.

> We have some progress already with the 'Echo Arena' game. I'll upload the Python sources that we have so far. Before continuing with the game, there was another experiment broken by the unsaved chat log. A customized AI agent in the Google AI Studio Chat, I was preparing it with the system prompt, I needed the article in markdown format to put there. Can you write it now? Also you gave couple of example prompts to test it.

The AI understood immediately and provided the necessary assets to get the specialist agent back online.

#### 1. The Manuscript as a System Prompt

First, it delivered the complete, final version of the paper—the one incorporating the Predictive Processing framework—formatted in Markdown, ready to be pasted into the system instructions of a new chat agent. This would imbue the agent with a deep, foundational knowledge of the theory.

*(Note: The full Markdown text of the paper is preserved in the dialogue logs.)*

#### 2. Recreated Test Prompts

Next, the AI recreated the set of diagnostic prompts they had designed to test the agent's understanding. These weren't simple keyword queries; they were designed to probe for genuine comprehension.

**Test Prompts for the Specialist Agent:**

*   **Test 1: Conceptual Explanation:** "In simple terms, explain the relationship between the 'Active Agent' and the 'Predictive UI'..."
    *   *Purpose:* To test if the agent could synthesize the core interface mechanism.

*   **Test 2: Critical Self-Analysis:** "According to the paper's own conclusion, what is the biggest unanswered question or 'black box' that remains in the model?"
    *   *Purpose:* To test if the agent could identify the model's self-acknowledged limitations.

*   **Test 3: Creative Application:** "Using the framework presented in the paper, propose a possible explanation for the human experience of 'dreams'."
    *   *Purpose:* To test if the agent could creatively extend the model to explain a new phenomenon.

*   **Test 4: Comparative Analysis:** "How does the paper's concept of an 'NPC' created by the learning loop differ from a typical, scripted NPC in a video game?"
    *   *Purpose:* To test for a nuanced understanding of the proposed mechanism.

*   **Test 5: Deeper Dive:** "What role does 'prediction error' play in the data harvesting stage of the Iterative Learning Loop?"
    *   *Purpose:* To test its understanding of a specific, technical detail from the Predictive Processing framework.

With these assets, Alexander was ready to rebuild the "expert in a box"—an AI that could not only discuss their theory, but critique it, extend it, and explain it. 